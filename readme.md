ğŸ¤– Customer Support Chat Agent
A demo customer support chat agent built with Streamlit, LangChain, and Ollama.
The agent can detect intents, analyze sentiment & urgency, call APIs (mocked), and escalate when needed. All interactions are logged locally for feedback and review.

âœ¨ Features
- Intent Detection (refunds, order status, billing, etc.)
- Sentiment & Urgency Analysis
- Tool Integration (mock APIs for orders, refunds, tickets)
- SQLite Logging (conversations, actions, feedback)
- Escalation Handling (fallbacks when confidence is low)
- Streamlit UI with quick-start buttons, typing indicator, badges, and feedback controls


ğŸ“‚ Project Structure
```text
customer_support_agent/
â”‚
â”œâ”€â”€ app.py                # Main Streamlit app (UI + agent interface)
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ settings.py       # Configs (Ollama model, thresholds, DB path)
â”‚   â””â”€â”€ intents.yaml      # Intent definitions
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ state.py          # Defines SupportAgentState TypedDict
â”‚   â”œâ”€â”€ workflow.py       # Workflow orchestration (nodes + transitions)
â”‚   â”œâ”€â”€ nodes/            # Modular pipeline nodes
â”‚   â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”‚   â”œâ”€â”€ classifier.py
â”‚   â”‚   â”œâ”€â”€ sentiment.py
â”‚   â”‚   â”œâ”€â”€ tools.py
â”‚   â”‚   â”œâ”€â”€ response.py
â”‚   â”‚   â”œâ”€â”€ verification.py
â”‚   â”‚   â”œâ”€â”€ fallback.py
â”‚   â”‚   â”œâ”€â”€ logger.py
â”‚   â”‚   â””â”€â”€ responses.py
â”‚   â””â”€â”€ utils.py          # Helper functions
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ ollama_client.py  # Wrapper for Ollama API
â”‚   â”œâ”€â”€ mock_api.py       # Simulated order/refund/ticket APIs
â”‚   â””â”€â”€ db_logger.py      # SQLite logging + feedback
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ logs/             # Stored logs (SQLite/JSON)
â”‚   â””â”€â”€ examples.json     # Example test queries
â”œâ”€â”€ requirements.txt      # Dependencies
â””â”€â”€ README.md             # Documentation
```


ğŸš€ Quick Start

1. Install Dependencies
- pip install -r requirements.txt

2. Install & Run Ollama
- Make sure you have Ollama installed and running locally.
Example (with llama3.1): ollama pull llama3.1 and then ollama serve
- By default, the app connects to http://localhost:11434.

3. Configure Settings
- Update config/settings.py if needed:

4. Run the Streamlit App
- streamlit run app.py


ğŸ›  Demo Notes
- Mock APIs are used for orders, refunds, and tickets (replace with real APIs for production).
- Logs are stored in SQLite (data/logs/support_logs.db) and can be inspected.
- Feedback can be given per response (ğŸ‘ / ğŸ‘).
- Debug Info can be toggled in the sidebar.

- PS: This is a demo (not production-ready).




